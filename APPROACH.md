# Methodology Explanation: Persona-Driven Intelligence

This document outlines the methodology behind the automated document analysis and intelligence extraction pipeline. The system's core objective is to emulate how a human expert would read a large volume of documents to find information relevant to a specific role and task. It achieves this through a multi-stage process that combines modern NLP techniques with robust heuristics.

---

### Phase 1: Document Ingestion and Relevance Filtering

The process begins by ingesting a user-defined **persona** (e.g., "a compliance officer"), a **job-to-be-done** (JTBD) (e.g., "identify risks related to new data privacy regulations"), and a collection of PDF documents.

1.  **Text Extraction:** Each PDF is processed page by page. The system uses `pdfplumber` to extract text while preserving layout information, which helps maintain reading order. Basic cleaning is performed to remove artifacts like running headers/footers and to de-hyphenate words broken across lines.

2.  **Initial Filtering:** To optimize performance, the system first performs a rapid, lightweight filtering of all extracted pages. It creates a "quick score" for each page based on the density of keywords and keyphrases derived from the persona and JTBD. This step efficiently discards a large number of irrelevant pages (e.g., title pages, tables of contents, irrelevant appendices) before committing to more computationally expensive analysis.

---

### Phase 2: Hybrid Scoring and Ranking

The filtered pages undergo a more sophisticated analysis.

1.  **Segmentation (Chunking):** Each page's content is broken down into smaller, overlapping text segments of approximately 400 words. This ensures that context is preserved within each segment and allows for a more granular analysis than scoring an entire page at once.

2.  **Hybrid Scoring Model:** Each segment is scored using a weighted, hybrid model that combines two distinct approaches:
    * **Semantic Similarity:** The system uses a pre-trained `spaCy` language model (`en_core_web_md`) to convert both the user query (persona + JTBD) and each text segment into numerical vectors, or **embeddings**. It then calculates the cosine similarity between the query vector and each segment vector. This score represents the *conceptual relevance* of the segment, even if it doesn't use the exact same keywords.
    * **Lexical Matching:** The system also calculates a score based on the overlap of specific keywords and keyphrases between the query and the segment. This ensures that segments containing critical, must-have terms are prioritized.

The final score for each segment is a weighted average of its semantic similarity, keyword score, and other heuristics like content length.

---

### Phase 3: Synthesis and Output

1.  **Ranking:** Segments are ranked by their final hybrid score. The system then aggregates these scores to identify the top 5 most relevant source documents.

2.  **Summarization & Titling:** For each top-ranked document, the system focuses on the page containing the single highest-scoring segment. The full text of this page is used to generate two key outputs:
    * A **Contextual Headline** is generated by analyzing N-grams and keyphrases from the page that are also relevant to the user's query.
    * A **Refined Summary** is created using the TextRank algorithm, a graph-based method that extracts the most salient and central sentences from the page to provide a concise overview.

The final output is a structured JSON file containing the ranked list of important document sections, each with a generated title, page number, and an executive summary, ready for user review. ðŸŽ¯